{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7cd104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Estimasi LMDB untuk: node_transaksi ===\n",
      "Rows: 24502104\n",
      "id_trx                         | string                    |    1093.32 MB\n",
      "id                             | string                    |     155.26 MB\n",
      "seq                            | string                    |     140.20 MB\n",
      "auxtrc                         | string                    |      93.47 MB\n",
      "dsctrc                         | string                    |     185.51 MB\n",
      "src                            | string                    |     257.79 MB\n",
      "amt                            | string                    |     303.33 MB\n",
      "dst                            | string                    |     260.11 MB\n",
      "curr                           | string                    |      93.47 MB\n",
      "cd                             | string                    |      23.37 MB\n",
      "channel                        | string                    |     934.68 MB\n",
      "\n",
      "TOTAL ESTIMATED SIZE: 3.46 GB\n",
      "RECOMMENDED LMDB MAP_SIZE: 5 GB\n",
      "\n",
      "\n",
      "===================== RINGKASAN MAP_SIZE =====================\n",
      "node_transaksi                           : 5 GB\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import os\n",
    "import math\n",
    "\n",
    "BYTES_PER_TYPE = {\n",
    "    \"int8\": 1, \"int16\": 2, \"int32\": 4, \"int64\": 8,\n",
    "    \"uint8\": 1, \"uint16\": 2, \"uint32\": 4, \"uint64\": 8,\n",
    "    \"float\": 4, \"float16\": 2, \"float32\": 4, \"float64\": 8,\n",
    "    \"bool\": 1,\n",
    "}\n",
    "\n",
    "STRING_DEFAULT_BYTES = 16\n",
    "\n",
    "def patch_schema(schema):\n",
    "    fields = []\n",
    "    for field in schema:\n",
    "        if pa.types.is_decimal(field.type):\n",
    "            fields.append(pa.field(field.name, pa.string()))\n",
    "        else:\n",
    "            fields.append(field)\n",
    "    return pa.schema(fields)\n",
    "\n",
    "\n",
    "def estimate_array_size(arr, col_type):\n",
    "    n = len(arr)\n",
    "\n",
    "    if pa.types.is_integer(col_type) or pa.types.is_floating(col_type):\n",
    "        dtype = col_type.to_pandas_dtype()\n",
    "        return n * BYTES_PER_TYPE.get(dtype, 8)\n",
    "\n",
    "    if pa.types.is_boolean(col_type):\n",
    "        return n * 1\n",
    "\n",
    "    if pa.types.is_decimal(col_type):\n",
    "        return n * 16\n",
    "\n",
    "    if pa.types.is_string(col_type):\n",
    "        # Sample 5000\n",
    "        sample = arr.slice(0, min(5000, n)).to_pylist()\n",
    "        total_len = sum(len(x) for x in sample if x is not None)\n",
    "        non_null = sum(1 for x in sample if x is not None)\n",
    "        avg_len = (total_len / non_null) if non_null > 0 else STRING_DEFAULT_BYTES\n",
    "        return int(n * avg_len)\n",
    "\n",
    "    return n * 16\n",
    "\n",
    "\n",
    "INPUT_DIR = \"D:\\\\zman\\\\graph\\\\data\"\n",
    "results = []\n",
    "\n",
    "for file in os.listdir(INPUT_DIR)[10:]:\n",
    "\n",
    "    if file.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(INPUT_DIR, file)\n",
    "\n",
    "    base = ds.dataset(path, format=\"parquet\", partitioning=\"hive\")\n",
    "    patched_schema = patch_schema(base.schema)\n",
    "    dataset = ds.dataset(path, format=\"parquet\", partitioning=\"hive\", schema=patched_schema)\n",
    "\n",
    "    print(f\"\\n=== Estimasi LMDB untuk: {file} ===\")\n",
    "\n",
    "    num_rows = dataset.count_rows()\n",
    "    print(\"Rows:\", num_rows)\n",
    "\n",
    "    total_bytes = 0\n",
    "\n",
    "    for col in dataset.schema.names:\n",
    "\n",
    "        col_type = dataset.schema.field(col).type\n",
    "        col_bytes = 0\n",
    "\n",
    "        # Scanner hanya untuk 1 kolom\n",
    "        scanner = dataset.scanner(columns=[col], batch_size=75_000)\n",
    "\n",
    "        for batch in scanner.to_batches():\n",
    "            arr = batch.column(0)\n",
    "            col_bytes += estimate_array_size(arr, col_type)\n",
    "\n",
    "        total_bytes += col_bytes\n",
    "\n",
    "        print(f\"{col:30} | {str(col_type):25} | {col_bytes/1024/1024:10.2f} MB\")\n",
    "\n",
    "    lmdb_bytes = int(total_bytes * 1.2)\n",
    "    gb = math.ceil(lmdb_bytes / (1024**3))\n",
    "\n",
    "    print(f\"\\nTOTAL ESTIMATED SIZE: {total_bytes/1024/1024/1024:.2f} GB\")\n",
    "    print(f\"RECOMMENDED LMDB MAP_SIZE: {gb} GB\\n\")\n",
    "\n",
    "    results.append((file, gb))\n",
    "\n",
    "print(\"\\n===================== RINGKASAN MAP_SIZE =====================\")\n",
    "for file, gb in results:\n",
    "    print(f\"{file:40} : {gb} GB\")\n",
    "print(\"==============================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d839ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Node: transaksi ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "817it [2:38:31, 11.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mapped: 12,516,002 node transaksi\n",
      "\n",
      "All mapping completed successfully!\n",
      "\n",
      "Final Node Counts:\n",
      "{\n",
      "    \"transaksi\": 12516002\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import lmdb\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "###########################################\n",
    "# CONFIG\n",
    "###########################################\n",
    "\n",
    "NODE_TABLES = {\n",
    "    # \"nasabah\": \"D:\\\\zman\\\\graph\\\\data\\\\node_nasabah\",          # Parquet directory (partitioned)\n",
    "    # \"pekerja\": \"D:\\\\zman\\\\graph\\\\data\\\\node_pekerja\",\n",
    "    # \"pinjaman\": \"D:\\\\zman\\\\graph\\\\data\\\\node_pinjaman\",\n",
    "    # \"simpanan\": \"D:\\\\zman\\\\graph\\\\data\\\\node_simpanan\",\n",
    "    \"transaksi\": \"D:\\\\zman\\\\graph\\\\data\\\\node_transaksi\",\n",
    "}\n",
    "\n",
    "ID_COLUMN = {\n",
    "    # \"nasabah\": \"cif\",\n",
    "    # \"pekerja\": \"pn\",\n",
    "    # \"pinjaman\": \"acctno\",\n",
    "    # \"simpanan\": \"acctno\",\n",
    "    \"transaksi\": \"id_trx\"\n",
    "}\n",
    "\n",
    "LMDB_PATH = \"lmdb_node_mapping\"\n",
    "# MAP_SIZE = 1024 * 1024 * 1024 * 50   # 50GB, adjust if necessary\n",
    "\n",
    "MAP_SIZE = {\n",
    "    # \"nasabah\": 1024 * 1024 * 1024 * 23,\n",
    "    # \"pekerja\": 1024 * 1024 * 1024 * 1,\n",
    "    # \"pinjaman\": 1024 * 1024 * 1024 * 3,\n",
    "    # \"simpanan\": 1024 * 1024 * 1024 * 34,\n",
    "    \"transaksi\": 1024 * 1024 * 1024 * 5\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 75_000  # Read parquet in chunks\n",
    "\n",
    "\n",
    "###########################################\n",
    "# UTILS\n",
    "###########################################\n",
    "\n",
    "def encode(x: str) -> bytes:\n",
    "    return x.encode()\n",
    "\n",
    "def decode(b: bytes) -> str:\n",
    "    return b.decode()\n",
    "\n",
    "\n",
    "###########################################\n",
    "# MAIN MAPPER FUNCTION\n",
    "###########################################\n",
    "def patch_schema(schema):\n",
    "    fields = []\n",
    "    for field in schema:\n",
    "        if pa.types.is_decimal(field.type):\n",
    "            # Convert DECIMAL to STRING\n",
    "            fields.append(pa.field(field.name, pa.string()))\n",
    "        else:\n",
    "            fields.append(field)\n",
    "    return pa.schema(fields)\n",
    "\n",
    "\n",
    "def build_node_mapping():\n",
    "    os.makedirs(LMDB_PATH, exist_ok=True)\n",
    "\n",
    "    envs = {}\n",
    "    for node_type in NODE_TABLES.keys():\n",
    "        envs[node_type] = lmdb.open(\n",
    "            os.path.join(LMDB_PATH, f\"{node_type}.lmdb\"),\n",
    "            map_size=MAP_SIZE[node_type],\n",
    "            subdir=True,\n",
    "            lock=True,\n",
    "            readonly=False,\n",
    "            max_dbs=1,\n",
    "        )\n",
    "\n",
    "    counters = {nt: 0 for nt in NODE_TABLES.keys()}\n",
    "\n",
    "    # Loop setiap tabel node\n",
    "    for node_type, folder in NODE_TABLES.items():\n",
    "        print(f\"\\n=== Processing Node: {node_type} ===\")\n",
    "        base = ds.dataset(folder, format=\"parquet\", partitioning=\"hive\")\n",
    "        patched_schema = patch_schema(base.schema)\n",
    "        dataset = ds.dataset(folder, format=\"parquet\", partitioning=\"hive\", schema=patched_schema)\n",
    "        \n",
    "        env = envs[node_type]\n",
    "        id_col = ID_COLUMN[node_type]\n",
    "        counter = counters[node_type]\n",
    "\n",
    "        # buka transaction manual\n",
    "        txn = env.begin(write=True)\n",
    "        \n",
    "        for batch in tqdm(dataset.to_batches(batch_size=30_000)):\n",
    "            batch_dict = batch.to_pydict()   # hindari ArrowDecimal error\n",
    "            \n",
    "            if id_col not in batch_dict:\n",
    "                raise KeyError(f\"Kolom {id_col} tidak ditemukan dalam batch. Schema: {batch.schema}\")\n",
    "            ids = batch_dict[id_col]\n",
    "\n",
    "        # for batch in dataset.to_batches(batch_size=BATCH_SIZE):\n",
    "        #     col = batch.column(batch.schema.get_field_index(id_col))\n",
    "        #     ids = col.to_pylist()\n",
    "\n",
    "            for node_id in ids:\n",
    "                if node_id is None:\n",
    "                    continue\n",
    "\n",
    "                key = encode(str(node_id))\n",
    "\n",
    "                if txn.get(key) is None:\n",
    "                    txn.put(key, encode(str(counter)))\n",
    "                    counter += 1\n",
    "\n",
    "            # Commit setiap batch utk mencegah long transaction\n",
    "            txn.commit()\n",
    "            txn = env.begin(write=True)\n",
    "\n",
    "        # Final commit & close\n",
    "        txn.commit()\n",
    "\n",
    "        counters[node_type] = counter\n",
    "        print(f\"Total mapped: {counter:,} node {node_type}\")\n",
    "\n",
    "    print(\"\\nAll mapping completed successfully!\")\n",
    "    return counters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# RUN\n",
    "###########################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = build_node_mapping()\n",
    "    print(\"\\nFinal Node Counts:\")\n",
    "    print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b6c7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "LMDB Path             : D:/zman/graph/notebook/lmdb_node_mapping/nasabah.lmdb\n",
      "---------------------------------------------------\n",
      "Total Unique Keys     : 12,270,075\n",
      "Nilai 'None' / Empty  : 0\n",
      "---------------------------------------------------\n",
      "Contoh Key-Value:\n",
      "   ('       ', 14414838833951025)\n",
      "   (' 002257', 57381655819064)\n",
      "   (' 002258', 15540712970926387)\n",
      "   (' 002259', 14981087305544759)\n",
      "   (' 002260', 14694110576587320)\n",
      "===================================================\n",
      "===================================================\n",
      "LMDB Path             : D:/zman/graph/notebook/lmdb_node_mapping/pekerja.lmdb\n",
      "---------------------------------------------------\n",
      "Total Unique Keys     : 6,250\n",
      "Nilai 'None' / Empty  : 0\n",
      "---------------------------------------------------\n",
      "Contoh Key-Value:\n",
      "   ('103016', 892941621)\n",
      "   ('103033', 859387189)\n",
      "   ('104542', 875706165)\n",
      "   ('112567', 892876595)\n",
      "   ('112616', 808924468)\n",
      "===================================================\n",
      "===================================================\n",
      "LMDB Path             : D:/zman/graph/notebook/lmdb_node_mapping/simpanan.lmdb\n",
      "---------------------------------------------------\n",
      "Total Unique Keys     : 15,636,712\n",
      "Nilai 'None' / Empty  : 0\n",
      "---------------------------------------------------\n",
      "Contoh Key-Value:\n",
      "   ('106201000001500', 14131160572703545)\n",
      "   ('106201000001526', 3617858594557932081)\n",
      "   ('106201000002506', 13565981564680499)\n",
      "   ('106201000002514', 13855191727289910)\n",
      "   ('106201000002522', 13851884535427377)\n",
      "===================================================\n",
      "===================================================\n",
      "LMDB Path             : D:/zman/graph/notebook/lmdb_node_mapping/pinjaman.lmdb\n",
      "---------------------------------------------------\n",
      "Total Unique Keys     : 1,524,589\n",
      "Nilai 'None' / Empty  : 0\n",
      "---------------------------------------------------\n",
      "Contoh Key-Value:\n",
      "   ('106201000007158', 55182665857330)\n",
      "   ('106201000013159', 60714550506034)\n",
      "   ('106201000015151', 56320849229624)\n",
      "   ('106201000026152', 60693008168503)\n",
      "   ('106201000062158', 57381706282293)\n",
      "===================================================\n",
      "===================================================\n",
      "LMDB Path             : D:/zman/graph/notebook/lmdb_node_mapping/transaksi.lmdb\n",
      "---------------------------------------------------\n",
      "Total Unique Keys     : 12,516,002\n",
      "Nilai 'None' / Empty  : 0\n",
      "---------------------------------------------------\n",
      "Contoh Key-Value:\n",
      "   ('100051710001423023570100066050210000000000', 13570413971387698)\n",
      "   ('10005370800162352350104698850430000000000', 15262549498016308)\n",
      "   ('1000537100008230276701002132500120000000000', 14128944302864437)\n",
      "   ('100105271200152123050500000472401046696536', 14135558619411249)\n",
      "   ('1001052736001221230200500000461701044504530', 14126753902900024)\n",
      "===================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12516002,\n",
       " 0,\n",
       " [('100051710001423023570100066050210000000000', 13570413971387698),\n",
       "  ('10005370800162352350104698850430000000000', 15262549498016308),\n",
       "  ('1000537100008230276701002132500120000000000', 14128944302864437),\n",
       "  ('100105271200152123050500000472401046696536', 14135558619411249),\n",
       "  ('1001052736001221230200500000461701044504530', 14126753902900024)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lmdb\n",
    "\n",
    "def inspect_lmdb(path, max_sample=5):\n",
    "    env = lmdb.open(path, readonly=True, lock=False)\n",
    "    total_keys = 0\n",
    "    none_values = 0\n",
    "    samples = []\n",
    "\n",
    "    with env.begin() as txn:\n",
    "        cursor = txn.cursor()\n",
    "\n",
    "        for key, val in cursor:\n",
    "            total_keys += 1\n",
    "\n",
    "            # val None tidak akan muncul pada LMDB, tapi val bisa empty\n",
    "            if val is None or len(val) == 0:\n",
    "                none_values += 1\n",
    "\n",
    "            if len(samples) < max_sample:\n",
    "                try:\n",
    "                    samples.append((key.decode(), int.from_bytes(val, \"little\")))\n",
    "                except:\n",
    "                    samples.append((key.decode(), val))\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"===================================================\")\n",
    "    print(f\"LMDB Path             : {path}\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(f\"Total Unique Keys     : {total_keys:,}\")\n",
    "    print(f\"Nilai 'None' / Empty  : {none_values:,}\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"Contoh Key-Value:\")\n",
    "    for s in samples:\n",
    "        print(\"  \", s)\n",
    "    print(\"===================================================\")\n",
    "\n",
    "    return total_keys, none_values, samples\n",
    "\n",
    "\n",
    "\n",
    "inspect_lmdb(\"D:/zman/graph/notebook/lmdb_node_mapping/nasabah.lmdb\")\n",
    "inspect_lmdb(\"D:/zman/graph/notebook/lmdb_node_mapping/pekerja.lmdb\")\n",
    "inspect_lmdb(\"D:/zman/graph/notebook/lmdb_node_mapping/simpanan.lmdb\")\n",
    "inspect_lmdb(\"D:/zman/graph/notebook/lmdb_node_mapping/pinjaman.lmdb\")\n",
    "inspect_lmdb(\"D:/zman/graph/notebook/lmdb_node_mapping/transaksi.lmdb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-project",
   "language": "python",
   "name": "graph-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
