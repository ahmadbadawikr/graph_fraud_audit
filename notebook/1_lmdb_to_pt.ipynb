{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import lmdb\n",
    "import torch\n",
    "import pickle\n",
    "import msgpack\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, wait, FIRST_COMPLETED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def wait_first_done(futures):\n",
    "    \"\"\"Wait until at least one future is done.\"\"\"\n",
    "    done, not_done = wait(futures, return_when=FIRST_COMPLETED)\n",
    "    return list(done), list(not_done)\n",
    "\n",
    "def write_chunk(edge_dir, chunk_id, src_arr, dst_arr):\n",
    "    \"\"\"Write one chunk file (.pt).\"\"\"\n",
    "    os.makedirs(edge_dir, exist_ok=True)\n",
    "    edge_index = torch.from_numpy(np.vstack([src_arr, dst_arr]).astype(np.int64))\n",
    "    path = os.path.join(edge_dir, f\"{chunk_id:06d}.pt\")\n",
    "    torch.save(edge_index, path)\n",
    "    return path\n",
    "\n",
    "def lmdb_to_pt_chunks(\n",
    "    lmdb_path: str,\n",
    "    outdir: str,\n",
    "    batch_size: int = 1_000_000,\n",
    "    workers: int = 4,\n",
    "    max_queue: int = 8,\n",
    "    separator: str = \",\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert LMDB edge-index (src,dst) → chunked .pt files for PyG.\n",
    "    Optimized for notebook usage & low memory (streaming).\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Reading LMDB from: {lmdb_path}\")\n",
    "    print(f\"Saving chunks to:  {outdir}\")\n",
    "    sep = separator.encode()\n",
    "\n",
    "    # Open LMDB efficiently\n",
    "    env = lmdb.open(\n",
    "        lmdb_path,\n",
    "        readonly=True,\n",
    "        lock=False,\n",
    "        readahead=False,   # good for SSD\n",
    "        max_readers=32\n",
    "    )\n",
    "\n",
    "    # Try reading LMDB entry count (best effort)\n",
    "    try:\n",
    "        with env.begin() as txn:\n",
    "            total_keys = txn.stat().get(\"entries\")\n",
    "    except:\n",
    "        total_keys = None\n",
    "\n",
    "    if total_keys:\n",
    "        print(f\"Total keys detected: {total_keys:,}\")\n",
    "    else:\n",
    "        print(\"Total keys cannot be detected, using open-ended iteration.\")\n",
    "\n",
    "    executor = ThreadPoolExecutor(max_workers=workers)\n",
    "    futures = []\n",
    "    chunk_id = 0\n",
    "\n",
    "    with env.begin(write=False) as txn:\n",
    "        cursor = txn.cursor()\n",
    "\n",
    "        batch_src = []\n",
    "        batch_dst = []\n",
    "\n",
    "        pbar = tqdm(\n",
    "            total=total_keys,\n",
    "            desc=f\"Processing {os.path.basename(lmdb_path)}\",\n",
    "            smoothing=0.1\n",
    "        )\n",
    "\n",
    "        for _, val in cursor:\n",
    "            try:\n",
    "                a, b = val.split(sep, 1)\n",
    "            except:\n",
    "                continue  # skip malformed\n",
    "\n",
    "            batch_src.append(int(a))\n",
    "            batch_dst.append(int(b))\n",
    "\n",
    "            # When batch full → flush to writer thread\n",
    "            if len(batch_src) >= batch_size:\n",
    "                src_np = np.fromiter(batch_src, dtype=np.int64)\n",
    "                dst_np = np.fromiter(batch_dst, dtype=np.int64)\n",
    "\n",
    "                # Limit queued tasks to avoid memory blow-up\n",
    "                while len(futures) >= max_queue:\n",
    "                    done, futures = wait_first_done(futures)\n",
    "                    for fut in done:\n",
    "                        fut.result()\n",
    "\n",
    "                fut = executor.submit(write_chunk, outdir, chunk_id, src_np, dst_np)\n",
    "                futures.append(fut)\n",
    "\n",
    "                chunk_id += 1\n",
    "                batch_src = []\n",
    "                batch_dst = []\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "        # last batch\n",
    "        if batch_src:\n",
    "            src_np = np.fromiter(batch_src, dtype=np.int64)\n",
    "            dst_np = np.fromiter(batch_dst, dtype=np.int64)\n",
    "\n",
    "            while len(futures) >= max_queue:\n",
    "                done, futures = wait_first_done(futures)\n",
    "                for fut in done:\n",
    "                    fut.result()\n",
    "\n",
    "            fut = executor.submit(write_chunk, outdir, chunk_id, src_np, dst_np)\n",
    "            futures.append(fut)\n",
    "            chunk_id += 1\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "    # final writes\n",
    "    print(\"Finalizing chunk writes...\")\n",
    "    for fut in tqdm(as_completed(futures), total=len(futures)):\n",
    "        fut.result()\n",
    "\n",
    "    executor.shutdown(wait=True)\n",
    "\n",
    "    print(f\"Conversion complete → {chunk_id} chunks written.\")\n",
    "    return chunk_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Convert LMDB edge-index to chunked .pt files for PyG\n",
      "Reading LMDB from: /Users/ymnzaman/Documents/Project/Graph/lmdb_edge_indexing/edge_nasabah_is_pekerja.lmdb\n",
      "Saving chunks to:  /Users/ymnzaman/Documents/Project/Graph/chunks/edge_nasabah_is_pekerja\n",
      "Total keys detected: 64,110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9fa67ae93754000851c77958af62be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing edge_nasabah_is_pekerja.lmdb:   0%|          | 0/64110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing chunk writes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f084cd6e6964c528b208e47e3a04156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete → 1 chunks written.\n",
      "Reading LMDB from: /Users/ymnzaman/Documents/Project/Graph/lmdb_edge_indexing/edge_nasabah_memiliki_pinj.lmdb\n",
      "Saving chunks to:  /Users/ymnzaman/Documents/Project/Graph/chunks/edge_nasabah_memiliki_pinj\n",
      "Total keys detected: 12,682,596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c004b519bd436696d228f243c6cf96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing edge_nasabah_memiliki_pinj.lmdb:   0%|          | 0/12682596 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing chunk writes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6604857800478d864e061d749177e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete → 13 chunks written.\n",
      "Reading LMDB from: /Users/ymnzaman/Documents/Project/Graph/lmdb_edge_indexing/edge_nasabah_memiliki_simp.lmdb\n",
      "Saving chunks to:  /Users/ymnzaman/Documents/Project/Graph/chunks/edge_nasabah_memiliki_simp\n",
      "Total keys detected: 187,998,376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1436ddc939a447c84b2014d6abd69a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing edge_nasabah_memiliki_simp.lmdb:   0%|          | 0/187998376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing chunk writes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a240ff719d63416b9b6fca7d942c5409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete → 188 chunks written.\n",
      "Reading LMDB from: /Users/ymnzaman/Documents/Project/Graph/lmdb_edge_indexing/edge_pinj_credit.lmdb\n",
      "Saving chunks to:  /Users/ymnzaman/Documents/Project/Graph/chunks/edge_pinj_credit\n",
      "Total keys detected: 1,006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7c0f2ba7794d409ab05530be50f815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing edge_pinj_credit.lmdb:   0%|          | 0/1006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing chunk writes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1901d783b43a4adf8ac1de81d2d1780e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete → 1 chunks written.\n",
      "Reading LMDB from: /Users/ymnzaman/Documents/Project/Graph/lmdb_edge_indexing/edge_pinj_debit.lmdb\n",
      "Saving chunks to:  /Users/ymnzaman/Documents/Project/Graph/chunks/edge_pinj_debit\n",
      "Total keys detected: 1,006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c7c56333754c5cb31e0efd933a16a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing edge_pinj_debit.lmdb:   0%|          | 0/1006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing chunk writes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5265329baeb0479293cf70c21e44745e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete → 1 chunks written.\n",
      "Reading LMDB from: /Users/ymnzaman/Documents/Project/Graph/lmdb_edge_indexing/edge_simp_credit.lmdb\n",
      "Saving chunks to:  /Users/ymnzaman/Documents/Project/Graph/chunks/edge_simp_credit\n",
      "Total keys detected: 394,667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8e1912aac1464ea30d0cee7b1c97e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing edge_simp_credit.lmdb:   0%|          | 0/394667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing chunk writes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd952bd36a34e55863afba120feb70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete → 1 chunks written.\n",
      "Reading LMDB from: /Users/ymnzaman/Documents/Project/Graph/lmdb_edge_indexing/edge_simp_debit.lmdb\n",
      "Saving chunks to:  /Users/ymnzaman/Documents/Project/Graph/chunks/edge_simp_debit\n",
      "Total keys detected: 387,529\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba7a85d42f64a5d8a3367664f21c865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing edge_simp_debit.lmdb:   0%|          | 0/387529 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing chunk writes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bb41385dd544769ec27a0a3331159a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete → 1 chunks written.\n",
      "All conversions done.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Convert LMDB edge-index to chunked .pt files for PyG\")\n",
    "edges = [\n",
    "    \"edge_nasabah_is_pekerja.lmdb\",\n",
    "    \"edge_nasabah_memiliki_pinj.lmdb\",\n",
    "    \"edge_nasabah_memiliki_simp.lmdb\",\n",
    "    'edge_pinj_credit.lmdb',\n",
    "    'edge_pinj_debit.lmdb',\n",
    "    'edge_simp_credit.lmdb',\n",
    "    'edge_simp_debit.lmdb',\n",
    "]\n",
    "\n",
    "for edge in edges:\n",
    "    lmdb_path = f\"/Users/ymnzaman/Documents/Project/Graph/lmdb_edge_indexing/{edge}\"\n",
    "    outdir = f\"/Users/ymnzaman/Documents/Project/Graph/chunks/{edge.replace('.lmdb','')}\"\n",
    "\n",
    "    lmdb_to_pt_chunks(\n",
    "        lmdb_path,\n",
    "        outdir,\n",
    "        batch_size=1_000_000,\n",
    "        workers=4,\n",
    "        max_queue=6,\n",
    "        separator=\",\"\n",
    "    )\n",
    "print(\"All conversions done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_first_done(futures):\n",
    "    done, not_done = wait(futures, return_when=FIRST_COMPLETED)\n",
    "    return list(done), list(not_done)\n",
    "\n",
    "def write_node_chunk(outdir, chunk_id, records):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    path = os.path.join(outdir, f\"{chunk_id:06d}.pt\")\n",
    "    torch.save(records, path)\n",
    "    return path\n",
    "\n",
    "def decode_value(val):\n",
    "    \"\"\"Decode LMDB value with multiple fallback strategies.\"\"\"\n",
    "    # Try msgpack\n",
    "    try:\n",
    "        return msgpack.unpackb(val, raw=False)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Try pickle\n",
    "    try:\n",
    "        return pickle.loads(val)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Try JSON\n",
    "    try:\n",
    "        return json.loads(val.decode())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Fallback: return raw bytes\n",
    "    return val\n",
    "\n",
    "\n",
    "def lmdb_node_to_pt_chunks(\n",
    "    lmdb_path: str,\n",
    "    outdir: str,\n",
    "    batch_size: int = 200_000,\n",
    "    workers: int = 4,\n",
    "    max_queue: int = 8,\n",
    "):\n",
    "    \"\"\"\n",
    "    Stream LMDB node → chunked .pt.\n",
    "    More general than edge converter because values vary (dicts, lists, etc.).\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Reading LMDB nodes from: {lmdb_path}\")\n",
    "    print(f\"Saving chunks to:        {outdir}\")\n",
    "    \n",
    "    env = lmdb.open(\n",
    "        lmdb_path,\n",
    "        readonly=True,\n",
    "        lock=False,\n",
    "        readahead=False,\n",
    "        max_readers=32\n",
    "    )\n",
    "\n",
    "    # detect total entries\n",
    "    try:\n",
    "        total_keys = env.stat()[\"entries\"]\n",
    "        print(f\"Total node entries: {total_keys:,}\")\n",
    "    except:\n",
    "        total_keys = None\n",
    "        print(\"Total entries cannot be detected.\")\n",
    "\n",
    "    executor = ThreadPoolExecutor(max_workers=workers)\n",
    "    futures = []\n",
    "    chunk_id = 0\n",
    "    \n",
    "    with env.begin(write=False) as txn:\n",
    "        cursor = txn.cursor()\n",
    "\n",
    "        batch_records = []\n",
    "        pbar = tqdm(total=total_keys, desc=\"Processing nodes\")\n",
    "\n",
    "        for key, val in cursor:\n",
    "            record = decode_value(val)\n",
    "            batch_records.append(record)\n",
    "\n",
    "            if len(batch_records) >= batch_size:\n",
    "\n",
    "                # wait if queue full\n",
    "                while len(futures) >= max_queue:\n",
    "                    done, futures = wait_first_done(futures)\n",
    "                    for fut in done:\n",
    "                        fut.result()\n",
    "\n",
    "                fut = executor.submit(\n",
    "                    write_node_chunk, outdir, chunk_id, batch_records\n",
    "                )\n",
    "                futures.append(fut)\n",
    "\n",
    "                chunk_id += 1\n",
    "                batch_records = []\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "        # last batch\n",
    "        if batch_records:\n",
    "            fut = executor.submit(\n",
    "                write_node_chunk, outdir, chunk_id, batch_records\n",
    "            )\n",
    "            futures.append(fut)\n",
    "            chunk_id += 1\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "    print(\"Finalizing chunk writes...\")\n",
    "    for fut in tqdm(as_completed(futures), total=len(futures)):\n",
    "        fut.result()\n",
    "\n",
    "    executor.shutdown(wait=True)\n",
    "\n",
    "    print(f\"Node conversion complete → {chunk_id} chunks written.\")\n",
    "    return chunk_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Convert LMDB map-node to chunked .pt files for PyG\n",
      "Reading LMDB nodes from: /Users/ymnzaman/Documents/Project/Graph/lmdb_node_mapping/nasabah.lmdb\n",
      "Saving chunks to:        /Users/ymnzaman/Documents/Project/Graph/chunks/nasabah\n",
      "Total node entries: 12,270,075\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f994ff2e93824a39bebeb64178f48b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing nodes:   0%|          | 0/12270075 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing chunk writes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a2134a4dc34acea0057f2112c430aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node conversion complete → 13 chunks written.\n",
      "Reading LMDB nodes from: /Users/ymnzaman/Documents/Project/Graph/lmdb_node_mapping/pekerja.lmdb\n",
      "Saving chunks to:        /Users/ymnzaman/Documents/Project/Graph/chunks/pekerja\n",
      "Total node entries: 6,250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5332c1fa5b4df4b61892a5ebf2553f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing nodes:   0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing chunk writes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4c63feb77645f0aed74578270b9e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node conversion complete → 1 chunks written.\n",
      "Reading LMDB nodes from: /Users/ymnzaman/Documents/Project/Graph/lmdb_node_mapping/pinjaman.lmdb\n",
      "Saving chunks to:        /Users/ymnzaman/Documents/Project/Graph/chunks/pinjaman\n",
      "Total node entries: 1,524,589\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d431c21e3547d3b80d0ec31e12b9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing nodes:   0%|          | 0/1524589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing chunk writes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fc78a6148f441cb0ec2959ea065e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node conversion complete → 2 chunks written.\n",
      "Reading LMDB nodes from: /Users/ymnzaman/Documents/Project/Graph/lmdb_node_mapping/simpanan.lmdb\n",
      "Saving chunks to:        /Users/ymnzaman/Documents/Project/Graph/chunks/simpanan\n",
      "Total node entries: 15,636,712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7599bc5f8c4c859ea1274b14f66ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing nodes:   0%|          | 0/15636712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing chunk writes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfbe904ec144106aefb2bebcd637b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node conversion complete → 16 chunks written.\n",
      "Reading LMDB nodes from: /Users/ymnzaman/Documents/Project/Graph/lmdb_node_mapping/transaksi.lmdb\n",
      "Saving chunks to:        /Users/ymnzaman/Documents/Project/Graph/chunks/transaksi\n",
      "Total node entries: 12,516,002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a9656801c248f49c9b1d975cdf7f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing nodes:   0%|          | 0/12516002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing chunk writes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be24723aa64a403895b8f8be74906366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node conversion complete → 13 chunks written.\n",
      "All conversions done.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Convert LMDB map-node to chunked .pt files for PyG\")\n",
    "nodes = [\n",
    "    \"nasabah.lmdb\",\n",
    "    \"pekerja.lmdb\",\n",
    "    \"pinjaman.lmdb\",\n",
    "    \"simpanan.lmdb\",\n",
    "    \"transaksi.lmdb\",\n",
    "]\n",
    "\n",
    "for node in nodes:\n",
    "    lmdb_path = f\"/Users/ymnzaman/Documents/Project/Graph/lmdb_node_mapping/{node}\"\n",
    "    outdir = f\"/Users/ymnzaman/Documents/Project/Graph/chunks/{node.replace('.lmdb','')}\"\n",
    "\n",
    "    lmdb_node_to_pt_chunks(\n",
    "        lmdb_path,\n",
    "        outdir,\n",
    "        batch_size=1_000_000,\n",
    "        workers=4,\n",
    "        max_queue=6,\n",
    "    )\n",
    "print(\"All conversions done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
